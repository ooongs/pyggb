# Parallel Dataset Creation Guide

ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ ëŒ€ëŸ‰ì˜ ê¸°í•˜í•™ ë¬¸ì œë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ë°©ë²• 1: Bash ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê°€ì¥ ê°„ë‹¨)

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ (4 workers, 5000 files)
./run_parallel_dataset.sh

# ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
./run_parallel_dataset.sh 8 5000 625  # 8 workers, 5000 files, 625 per batch
```

### ë°©ë²• 2: ìˆ˜ë™ìœ¼ë¡œ ì—¬ëŸ¬ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰

```bash
# í„°ë¯¸ë„ 1
python create_dataset.py --start 0 --end 1000

# í„°ë¯¸ë„ 2
python create_dataset.py --start 1000 --end 2000

# í„°ë¯¸ë„ 3
python create_dataset.py --start 2000 --end 3000

# í„°ë¯¸ë„ 4
python create_dataset.py --start 3000 --end 4000

# í„°ë¯¸ë„ 5
python create_dataset.py --start 4000 --end 5007

# ëª¨ë“  í„°ë¯¸ë„ ì™„ë£Œ í›„ merge
python create_dataset.py --merge
```

---

## ğŸ“– ìƒì„¸ ì‚¬ìš©ë²•

### create_dataset.py ì˜µì…˜

```bash
python create_dataset.py [OPTIONS]

Options:
  --input-dir DIR      ì…ë ¥ ë””ë ‰í† ë¦¬ (default: data-5/GeoQA3/json)
  --output-dir DIR     ì¶œë ¥ ë””ë ‰í† ë¦¬ (default: ground_truth)
  --start N            ì‹œì‘ ì¸ë±ìŠ¤ (inclusive)
  --end N              ë ì¸ë±ìŠ¤ (exclusive)
  --merge              ëª¨ë“  JSONL íŒŒì¼ì„ í•˜ë‚˜ì˜ JSONìœ¼ë¡œ ë³‘í•©
  --no-resume          ì´ë¯¸ ì²˜ë¦¬ëœ IDë¥¼ ë‹¤ì‹œ ì²˜ë¦¬
  --model MODEL        ì‚¬ìš©í•  OpenAI ëª¨ë¸ (default: gpt-4.1-mini)
```

### ì˜ˆì‹œ

```bash
# ì „ì²´ íŒŒì¼ ì²˜ë¦¬ (ìˆœì°¨ì )
python create_dataset.py

# ë²”ìœ„ ì§€ì • ì²˜ë¦¬ (0~500)
python create_dataset.py --start 0 --end 500

# ë²”ìœ„ ì§€ì • ì²˜ë¦¬ (500~1000)
python create_dataset.py --start 500 --end 1000

# ì»¤ìŠ¤í…€ ì¶œë ¥ ë””ë ‰í† ë¦¬
python create_dataset.py --start 0 --end 100 --output-dir my_output

# resume ë¹„í™œì„±í™” (ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬)
python create_dataset.py --start 0 --end 100 --no-resume

# ëª¨ë“  JSONL íŒŒì¼ ë³‘í•©
python create_dataset.py --merge --output-dir ground_truth
```

---

## ğŸ”„ ë™ì‘ ë°©ì‹

### 1. ì¦ë¶„ ì €ì¥ (Incremental Saving)

ê° ë¬¸ì œë¥¼ íŒŒì‹±í•  ë•Œë§ˆë‹¤ ì¦‰ì‹œ JSONL íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤:

```
ground_truth/
â”œâ”€â”€ dataset_0_1000.jsonl      # Worker 1 ê²°ê³¼
â”œâ”€â”€ dataset_1000_2000.jsonl   # Worker 2 ê²°ê³¼
â”œâ”€â”€ dataset_2000_3000.jsonl   # Worker 3 ê²°ê³¼
â””â”€â”€ ...
```

**ì¥ì :**

- ì¤‘ê°„ì— í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì–´ë„ ë°ì´í„° ì†ì‹¤ ì—†ìŒ
- Resume ëª¨ë“œë¡œ ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ ê°€ëŠ¥
- ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ê° workerê°€ ë…ë¦½ì ìœ¼ë¡œ íŒŒì¼ì— ê¸°ë¡

### 2. Resume ëª¨ë“œ

ì¶œë ¥ ë””ë ‰í† ë¦¬ì˜ **ëª¨ë“ ** JSONL íŒŒì¼ì„ ê²€ì‚¬í•˜ì—¬ ì´ë¯¸ ì²˜ë¦¬ëœ IDë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤:

```bash
# ì²« ë²ˆì§¸ ì‹¤í–‰ (0~500 ì²˜ë¦¬)
python create_dataset.py --start 0 --end 500
# â†’ 500ê°œ ì²˜ë¦¬ë¨

# ë‘ ë²ˆì§¸ ì‹¤í–‰ (0~1000ìœ¼ë¡œ í™•ì¥)
python create_dataset.py --start 0 --end 1000
# â†’ ê¸°ì¡´ 500ê°œëŠ” ìŠ¤í‚µ, ìƒˆë¡œìš´ 500ê°œë§Œ ì²˜ë¦¬
```

### 3. ë³‘í•© (Merge)

ëª¨ë“  JSONL íŒŒì¼ì„ í•˜ë‚˜ì˜ JSON ë°ì´í„°ì…‹ìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤:

```bash
python create_dataset.py --merge
```

**ë³‘í•© ê²°ê³¼:**

- ì¤‘ë³µ ID ìë™ ì œê±°
- í†µê³„ ìë™ ìƒì„± (ì¹´í…Œê³ ë¦¬/ë‚œì´ë„ ë¶„í¬)
- ìµœì¢… JSON íŒŒì¼ ìƒì„±

---

## ğŸ“ ì¶œë ¥ íŒŒì¼ í˜•ì‹

### JSONL íŒŒì¼ (ì¤‘ê°„ ê²°ê³¼)

ê° ì¤„ì´ í•˜ë‚˜ì˜ JSON ê°ì²´:

```jsonl
{"id": "0", "status": "parsed", "category": "Triangle", ...}
{"id": "1", "status": "parsed", "category": "Circle", ...}
{"id": "22", "status": "skipped", "reason": "ambiguous_reference"}
{"id": "33", "status": "error", "error": "Connection error"}
```

### JSON íŒŒì¼ (ìµœì¢… ê²°ê³¼)

```json
{
  "metadata": {
    "created_at": "2024-12-05T22:08:00",
    "total_problems": 4000,
    "skipped": 800,
    "errors": 7,
    "skipped_ids": ["22", "45", ...],
    "error_ids": ["33", ...]
  },
  "problems": [
    {
      "id": "0",
      "original_text": "...",
      "cleaned_text": "...",
      "category": "Triangle Properties & Constructions",
      "difficulty": 3,
      "required_objects": {...},
      "verification_conditions": [...]
    },
    ...
  ]
}
```

---

## ğŸ› ï¸ ë³‘ë ¬ ì²˜ë¦¬ ì „ëµ

### ê¶Œì¥ ì„¤ì •

| ì´ íŒŒì¼ ìˆ˜ | Workers | Batch Size | ì˜ˆìƒ ì‹œê°„ (API) |
| ---------- | ------- | ---------- | --------------- |
| 1,000      | 2       | 500        | ~30ë¶„           |
| 5,000      | 4       | 1,250      | ~2ì‹œê°„          |
| 5,000      | 8       | 625        | ~1ì‹œê°„          |
| 10,000     | 8       | 1,250      | ~2ì‹œê°„          |

**ì°¸ê³ :** ì‹œê°„ì€ ë„¤íŠ¸ì›Œí¬ ì†ë„ì™€ API ì‘ë‹µ ì‹œê°„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

### Bash ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
# ê¸°ë³¸ ì‹¤í–‰
./run_parallel_dataset.sh

# 8 workersë¡œ 5007ê°œ íŒŒì¼ ì²˜ë¦¬
./run_parallel_dataset.sh 8 5007

# ì»¤ìŠ¤í…€ batch size
./run_parallel_dataset.sh 4 5000 500
```

### ìˆ˜ë™ ì‹¤í–‰ (ë” ë§ì€ ì œì–´)

ì—¬ëŸ¬ í„°ë¯¸ë„ì—ì„œ ë™ì‹œ ì‹¤í–‰:

```bash
# Terminal 1
python create_dataset.py --start 0 --end 1250

# Terminal 2
python create_dataset.py --start 1250 --end 2500

# Terminal 3
python create_dataset.py --start 2500 --end 3750

# Terminal 4
python create_dataset.py --start 3750 --end 5007

# ì™„ë£Œ í›„ ë³‘í•©
python create_dataset.py --merge
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. API Rate Limits

OpenAI APIëŠ” rate limitì´ ìˆìŠµë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ workersë¥¼ ì‚¬ìš©í•˜ë©´ rate limitì— ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•´ê²° ë°©ë²•:**

- Workers ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜
- ê° worker ì‚¬ì´ì— ë”œë ˆì´ ì¶”ê°€

### 2. íŒŒì¼ ì ê¸ˆ (File Locking)

JSONL íŒŒì¼ì— ì“¸ ë•Œ `fcntl.flock`ì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì“°ê¸°ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
ê°™ì€ ë²”ìœ„ë¥¼ ì—¬ëŸ¬ workerê°€ ì²˜ë¦¬í•˜ë©´ ì¤‘ë³µì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë²”ìœ„ê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.

### 3. ë©”ëª¨ë¦¬ ì‚¬ìš©

ë³‘í•© ì‹œ ëª¨ë“  JSONL íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤. ë§¤ìš° í° ë°ì´í„°ì…‹ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¤‘ë‹¨ í›„ ì¬ê°œ

```bash
# Resume ëª¨ë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìŒ
python create_dataset.py --start 0 --end 5000
# ì¤‘ë‹¨ë¨...

# ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒì€ ìë™ìœ¼ë¡œ ìŠ¤í‚µ
python create_dataset.py --start 0 --end 5000
```

### íŠ¹ì • ë²”ìœ„ë§Œ ì¬ì²˜ë¦¬

```bash
# --no-resume ì˜µì…˜ ì‚¬ìš©
python create_dataset.py --start 1000 --end 2000 --no-resume
```

### ë¡œê·¸ í™•ì¸

Bash ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© ì‹œ ë¡œê·¸ëŠ” `logs/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:

```bash
# ë¡œê·¸ í™•ì¸
tail -f logs/worker_0_0_1250.log
tail -f logs/worker_1_1250_2500.log
```

### API ì˜¤ë¥˜

API ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ rule-based íŒŒì‹±ìœ¼ë¡œ fallbackë©ë‹ˆë‹¤.
ì˜¤ë¥˜ê°€ ê¸°ë¡ëœ IDëŠ” ë³‘í•© ì‹œ `error_ids`ì— í¬í•¨ë©ë‹ˆë‹¤.

---

## ğŸ“Š ê²°ê³¼ í™•ì¸

### ë³‘í•© í›„ í†µê³„ í™•ì¸

```bash
python create_dataset.py --merge
```

ì¶œë ¥ ì˜ˆì‹œ:

```
============================================================
Merge Complete!
============================================================
  Total parsed: 4000
  Total skipped: 800
  Total errors: 7
  Output: ground_truth/geoqa3_dataset.json

Category Distribution:
  Triangle Properties & Constructions     : 1200 (30.0%)
  Angle Relationships                     :  800 (20.0%)
  Circle Properties & Constructions       :  600 (15.0%)
  ...

Difficulty Distribution:
  Level 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (600)
  Level 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (1400)
  Level 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (1200)
  Level 4: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (600)
  Level 5: â–ˆâ–ˆâ–ˆâ–ˆ (200)
```

### JSON íŒŒì¼ ë¶„ì„

```python
import json

with open('ground_truth/geoqa3_dataset.json', 'r') as f:
    data = json.load(f)

print(f"Total problems: {len(data['problems'])}")
print(f"Skipped: {data['metadata']['skipped']}")
print(f"Errors: {data['metadata']['errors']}")
```

---

## ğŸ¯ ìµœì ì˜ ì›Œí¬í”Œë¡œìš°

1. **ì¤€ë¹„:**

   ```bash
   export OPENAI_API_KEY='your-key'
   ```

2. **ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰:**

   ```bash
   ./run_parallel_dataset.sh 4 5007
   ```

3. **ì§„í–‰ ìƒí™© í™•ì¸:**

   ```bash
   # ë¡œê·¸ í™•ì¸
   tail -f logs/worker_*.log

   # ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜ í™•ì¸
   wc -l ground_truth/dataset_*.jsonl
   ```

4. **ë³‘í•©:**

   ```bash
   python create_dataset.py --merge
   ```

5. **ê²°ê³¼ í™•ì¸:**
   ```bash
   cat ground_truth/geoqa3_dataset.json | python -m json.tool | head -50
   ```

---

## ğŸ’¡ íŒ

1. **ì‘ì€ í…ŒìŠ¤íŠ¸ ë¨¼ì €:** ì „ì²´ ì²˜ë¦¬ ì „ì— ì‘ì€ ë²”ìœ„ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.

   ```bash
   python create_dataset.py --start 0 --end 100
   ```

2. **ë¡œê·¸ ëª¨ë‹ˆí„°ë§:** ë³‘ë ¬ ì‹¤í–‰ ì‹œ ë¡œê·¸ë¥¼ ì£¼ì‹œí•˜ì„¸ìš”.

   ```bash
   watch -n 5 'wc -l ground_truth/dataset_*.jsonl'
   ```

3. **ì•¼ê°„ ì‹¤í–‰:** ëŒ€ëŸ‰ ì²˜ë¦¬ëŠ” ì•¼ê°„ì— ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

4. **ë°±ì—…:** ì¤‘ìš”í•œ ê²°ê³¼ëŠ” ë³‘í•© í›„ ë°±ì—…í•˜ì„¸ìš”.
   ```bash
   cp ground_truth/geoqa3_dataset.json ground_truth/geoqa3_dataset_backup.json
   ```



